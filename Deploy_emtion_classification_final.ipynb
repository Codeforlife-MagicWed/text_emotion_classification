{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dXV8MfQCpRME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8c30e9-6aaa-4e38-9046-12f949c84927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit transformers torch pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx chardet"
      ],
      "metadata": {
        "id": "3Ev4R9fRg-ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbba598d-ac29-4cff-8f00-5c498a67034d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly\n"
      ],
      "metadata": {
        "id": "Unu2BjmtmMRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1ab96e-2b3c-47d0-ec5a-818cb6b834c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "VrXkhlS4CxEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7df15a8-184e-4d5d-a74c-5d9340869836"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnc8L6uxpnsF",
        "outputId": "08369cc5-f1eb-49d0-938b-4d7b4fcaef86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UatTWENeM6Fw",
        "outputId": "1eec9fb1-d63b-4959-85c2-3684970786ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import docx\n",
        "import spacy\n",
        "import plotly.graph_objects as go\n",
        "import sys\n",
        "\n",
        "print(\"🚀 Streamlit Python:\", sys.executable, flush=True)\n",
        "\n",
        "# ---- Page setup ----\n",
        "st.set_page_config(page_title=\"Emotion Classifier\", page_icon=\"🎯\", layout=\"wide\")\n",
        "\n",
        "# ---- Header UI ----\n",
        "st.markdown(\"\"\"\n",
        "    <h1 style='text-align: center; color: #FF8C00;'>🎯 Emotion Classifier</h1>\n",
        "    <p style='text-align: center;'>Analyze emotional tone from text or document using DeBERTa</p>\n",
        "    <hr style='border-top: 1px solid #bbb;'>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ---- Load spaCy ----\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ---- Model config ----\n",
        "MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
        "LABELS = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
        "EMOTION_DESCRIPTIONS = {\n",
        "    \"joy\": \"Joy, happiness, contentment\",\n",
        "    \"sadness\": \"Sadness, pain, grief\",\n",
        "    \"anger\": \"Anger, frustration, rage\",\n",
        "    \"surprise\": \"Surprise, shock, amazement\",\n",
        "    \"disgust\": \"Disgust, repulsion, disapproval\",\n",
        "    \"fear\": \"Fear, anxiety, worry\",\n",
        "    \"neutral\": \"No clear emotion or neutral tone\"\n",
        "}\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=len(LABELS))\n",
        "    state_dict = torch.load(\"/content/drive/MyDrive/deberta_goemotions_epoch1.pth\", map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return tokenizer, model, device\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    doc = nlp(text)\n",
        "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "def plot_emotion_radar_plotly(labels, probs, title=\"Emotion Radar\"):\n",
        "    values = list(probs)\n",
        "    dominant_label = labels[np.argmax(probs)]\n",
        "    COLOR_BY_EMOTION = {\n",
        "        \"joy\": \"#FFD700\", \"sadness\": \"#4169E1\", \"anger\": \"#DC143C\", \"fear\": \"#800080\",\n",
        "        \"surprise\": \"#00CED1\", \"disgust\": \"#556B2F\", \"neutral\": \"#AAAAAA\"\n",
        "    }\n",
        "    line_color = COLOR_BY_EMOTION.get(dominant_label, \"#00BFFF\")\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=values + [values[0]],\n",
        "        theta=labels + [labels[0]],\n",
        "        fill='toself',\n",
        "        name='Emotions',\n",
        "        line=dict(color=line_color, width=3),\n",
        "        marker=dict(size=8),\n",
        "        hoverinfo='all'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        polar=dict(\n",
        "            bgcolor=\"#1e1e1e\",\n",
        "            gridshape=\"linear\",\n",
        "            radialaxis=dict(visible=True, range=[0, 1], tickfont=dict(color='white')),\n",
        "            angularaxis=dict(tickfont=dict(color='white'))\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        paper_bgcolor=\"#121212\",\n",
        "        font=dict(color=\"white\")\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def highlight_max_emotion(row):\n",
        "    emotions = row[LABELS]\n",
        "    max_idx = np.argmax(emotions)\n",
        "    return [\n",
        "        \"background-color: rgba(249,136,102,0.2); font-weight: 500\" if i == max_idx else \"\"\n",
        "        for i in range(len(emotions))\n",
        "    ]\n",
        "\n",
        "# ---- Load model ----\n",
        "tokenizer, model, device = load_model()\n",
        "\n",
        "# ---- Tabs UI ----\n",
        "tab1, tab2 = st.tabs([\"📝 Text Input\", \"📁 Upload File\"])\n",
        "\n",
        "# ==== TAB 1: TEXT INPUT ====\n",
        "with tab1:\n",
        "    text = st.text_area(\"\", placeholder=\"Enter your text here...\")\n",
        "    threshold = st.slider(\"Prediction threshold\", 0.1, 0.9, 0.3, 0.05)\n",
        "\n",
        "    if st.button(\"Predict\", key=\"btn_text\") and text.strip():\n",
        "        sentences = split_into_sentences(text)\n",
        "        st.markdown(f\"🔍 Detected **{len(sentences)}** sentences.\")\n",
        "\n",
        "        results = []\n",
        "        for sent in sentences:\n",
        "            inputs = tokenizer(sent, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(**inputs).logits\n",
        "                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "            results.append([sent] + list(probs))\n",
        "\n",
        "        df = pd.DataFrame(results, columns=[\"Sentence\"] + LABELS)\n",
        "        mean_probs = df[LABELS].mean().tolist()\n",
        "\n",
        "        col1, col2 = st.columns([1, 2])\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"🎯 Overall Emotion Summary\")\n",
        "            significant = [(l, p) for l, p in zip(LABELS, mean_probs) if p >= threshold]\n",
        "            if significant:\n",
        "                for label, prob in significant:\n",
        "                    desc = EMOTION_DESCRIPTIONS.get(label, \"\")\n",
        "                    st.markdown(f\"- **{label.capitalize()}**: `{prob:.2f}` – _{desc}_\")\n",
        "            else:\n",
        "                max_idx = int(np.argmax(mean_probs))\n",
        "                label = LABELS[max_idx]\n",
        "                st.markdown(f\"- **{label.capitalize()}**: `{mean_probs[max_idx]:.2f}` (highest) – _{EMOTION_DESCRIPTIONS[label]}_\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"📊 Overall Emotion Radar\")\n",
        "            radar_buf = plot_emotion_radar_plotly(LABELS, mean_probs)\n",
        "            st.plotly_chart(radar_buf, use_container_width=True, key=\"radar_text_input\")\n",
        "\n",
        "        st.subheader(\"📋 Sentence-level Predictions\")\n",
        "        styled_df = df.style.apply(highlight_max_emotion, axis=1, subset=LABELS)\n",
        "        st.dataframe(styled_df, use_container_width=True)\n",
        "\n",
        "\n",
        "# ==== TAB 2: FILE UPLOAD ====\n",
        "with tab2:\n",
        "    uploaded_file = st.file_uploader(\"Upload a .txt or .docx file\", type=[\"txt\", \"docx\"])\n",
        "    threshold = st.slider(\"Prediction threshold\", 0.1, 0.9, 0.3, 0.05, key=\"slider_file\")\n",
        "\n",
        "    if uploaded_file:\n",
        "        if uploaded_file.name.endswith(\".txt\"):\n",
        "            text = uploaded_file.read().decode(\"utf-8\")\n",
        "        elif uploaded_file.name.endswith(\".docx\"):\n",
        "            doc = docx.Document(uploaded_file)\n",
        "            text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "        else:\n",
        "            st.warning(\"Unsupported file format.\")\n",
        "            text = \"\"\n",
        "\n",
        "        if text:\n",
        "            sentences = split_into_sentences(text)\n",
        "            st.markdown(f\"🔍 Detected **{len(sentences)}** sentences.\")\n",
        "\n",
        "            results = []\n",
        "            for sent in sentences:\n",
        "                inputs = tokenizer(sent, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "                with torch.no_grad():\n",
        "                    logits = model(**inputs).logits\n",
        "                    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "                results.append([sent] + list(probs))\n",
        "\n",
        "            df = pd.DataFrame(results, columns=[\"Sentence\"] + LABELS)\n",
        "\n",
        "            col1, col2 = st.columns([1, 2])\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(\"🎯 Overall Emotion Summary\")\n",
        "                mean_probs = df[LABELS].mean().tolist()\n",
        "                significant = [(l, p) for l, p in zip(LABELS, mean_probs) if p >= threshold]\n",
        "                if significant:\n",
        "                    for label, prob in significant:\n",
        "                        desc = EMOTION_DESCRIPTIONS.get(label, \"\")\n",
        "                        st.markdown(f\"- **{label.capitalize()}**: `{prob:.2f}` – _{desc}_\")\n",
        "                else:\n",
        "                    max_idx = int(np.argmax(mean_probs))\n",
        "                    label = LABELS[max_idx]\n",
        "                    st.markdown(f\"- **{label.capitalize()}**: `{mean_probs[max_idx]:.2f}` (highest) – _{EMOTION_DESCRIPTIONS[label]}_\")\n",
        "\n",
        "            with col2:\n",
        "                st.subheader(\"📊 Overall Emotion Radar\")\n",
        "                fig = plot_emotion_radar_plotly(LABELS, mean_probs)\n",
        "                st.plotly_chart(fig, use_container_width=True, key=\"radar_file_input\")\n",
        "\n",
        "            st.subheader(\"📄 Sentence-level Predictions\")\n",
        "            styled_df = df.style.apply(highlight_max_emotion, axis=1, subset=LABELS)\n",
        "            st.dataframe(styled_df, use_container_width=True)\n",
        "            csv = df.to_csv(index=False).encode(\"utf-8\")\n",
        "            st.download_button(\"⬇️ Download Results (.csv)\", data=csv, file_name=\"emotion_analysis.csv\", mime=\"text/csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E_O04ropnqb",
        "outputId": "ca20aaa4-16d5-4abc-be6b-b4c80c00b6b0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2zGqw93wHrCFlYVk8E0yiqgeQUe_6AeYt8RWweFj9Q237XaLE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB842tlPl_cT",
        "outputId": "ea13742f-e8be-4a04-8a12-af0af980a573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!pkill -f streamlit\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "7m5540oRaT1f"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "def run():\n",
        "    !streamlit run app.py --server.headless true --server.port 8501\n",
        "\n",
        "threading.Thread(target=run, daemon=True).start()\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(\"http://localhost:8501\")\n",
        "print(\"🌐 App is live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUdL7AvYp6MR",
        "outputId": "6e0f4f45-e11e-4282-cb51-b4c420dfd955"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.91.83.166:8501\u001b[0m\n",
            "\u001b[0m\n",
            "🌐 App is live at: NgrokTunnel: \"https://fb43-34-91-83-166.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p23DLQ1RuVvN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}